{"version":3,"file":"static/js/743.6ed825ad.chunk.js","mappings":"kPAQe,SAASA,IACtB,MAAOC,EAAWC,IAAgBC,EAAAA,EAAAA,WAAS,IACpCC,EAAYC,IAAiBF,EAAAA,EAAAA,UAAS,KACtCG,EAAUC,IAAeJ,EAAAA,EAAAA,UAAS,KAClCK,EAAQC,IAAaN,EAAAA,EAAAA,UAAS,IAC/BO,GAAiBC,EAAAA,EAAAA,QAAO,OACxB,QAAEC,IAAYC,EAAAA,EAAAA,MAEpBC,EAAAA,EAAAA,WAAU,KACR,MAAMC,EACJC,OAAOD,mBAAqBC,OAAOC,wBAErC,IAAKF,EAEH,YADAG,MAAM,qDAIR,MAAMC,EAAc,IAAIJ,EACxBI,EAAYC,KAAO,QACnBD,EAAYE,YAAa,EACzBF,EAAYG,gBAAiB,EAE7BH,EAAYI,SAAYC,IACtB,IAAIC,EAAO,GACX,IAAK,IAAIC,EAAIF,EAAMG,YAAaD,EAAIF,EAAMI,QAAQC,OAAQH,IACxDD,GAAQD,EAAMI,QAAQF,GAAG,GAAGI,WAE9BzB,EAAcoB,GAEVD,EAAMI,QAAQJ,EAAMI,QAAQC,OAAS,GAAGE,SAC1CC,EAAiBP,IAIrBN,EAAYc,MAAQ,IAAM/B,GAAa,GACvCQ,EAAewB,QAAUf,GACxB,IAEH,MAAMa,EAAmBG,UACvB,MAAMC,EAAQX,EAAKY,eAGfD,EAAME,SAAS,cAAgBF,EAAME,SAAS,kBAChD1B,EAAQa,GAIV,IAAIc,EAAQ,GACZ,IACEA,QCxDCJ,eAA2BK,GAChC,IACE,MAAMC,QAAYC,MAAM,iCAAkC,CACxDC,OAAQ,OACRC,QAAS,CAAE,eAAgB,oBAC3BC,KAAMC,KAAKC,UAAU,CAAEP,cAGzB,aADmBC,EAAIO,QACXT,KACd,CAAE,MAAOU,GAEP,OADAC,QAAQC,MAAMF,GACP,qCACT,CACF,CD2CoBG,CAAY3B,EAC5B,CAAE,MAAOwB,GACPV,EAAQ,kCACRW,QAAQC,MAAM,sBAAuBF,EACvC,CACA1C,EAAYgC,GACZc,EAAUd,GAGV,UACQe,EAAAA,EAAAA,KAAOC,EAAAA,EAAAA,IAAWC,EAAAA,GAAI,iBAAkB,CAC5CC,KAAMhC,EACNiC,IAAKnB,EACLoB,UAAWC,EAAAA,GAAUC,QAEvBpD,EAAU,0CACVyC,QAAQY,IAAI,kCAAmC,CAAEL,KAAMhC,EAAMiC,IAAKnB,GACpE,CAAE,MAAOY,GACP1C,EAAU,uCACVyC,QAAQC,MAAM,uBAAwBA,EACxC,CAEAY,WAAW,IAAMtD,EAAU,IAAK,MAmB5B4C,EAAa5B,IACjB,IAAKT,OAAOgD,gBAAiB,OAC7B,MAAMC,EAAY,IAAIC,yBAAyBzC,GAC/CwC,EAAU7C,KAAO,QACjB6C,EAAUE,MAAQ,EAClBF,EAAUG,KAAO,EACjBpD,OAAOgD,gBAAgBK,MAAMJ,IAS/B,OACEK,EAAAA,EAAAA,MAAA,OAAKC,UAAU,sBAAqBC,SAAA,EAClCC,EAAAA,EAAAA,KAAA,OAAKF,UAAU,kBAAiBC,UAC9BC,EAAAA,EAAAA,KAAA,OAAKC,IAAKC,EAAMC,IAAI,gBAEtBN,EAAAA,EAAAA,MAAA,OAAKC,UAAU,iBAAgBC,SAAA,EAC7BC,EAAAA,EAAAA,KAAA,MAAAD,SAAI,yCACJC,EAAAA,EAAAA,KAAA,KAAAD,SAAG,iGAEHF,EAAAA,EAAAA,MAAA,OAAKC,UAAU,gBAAeC,SAAA,EAC5BC,EAAAA,EAAAA,KAAA,UACEF,UAAWtE,EAAY,kBAAoB,mBAC3C4E,QAAS5E,EAlCG6E,KAChBpE,EAAewB,UACjBxB,EAAewB,QAAQ6C,OACvB7E,GAAa,KAZM8E,KACjBtE,EAAewB,UACjB7B,EAAc,IACdE,EAAY,IACZG,EAAewB,QAAQ+C,QACvB/E,GAAa,KAsC6CsE,SAEnDvE,EAAY,iBAAmB,qBAElCwE,EAAAA,EAAAA,KAAA,UAAQF,UAAU,iBAAiBM,QAtBtBK,KACflE,OAAOgD,iBACThD,OAAOgD,gBAAgBmB,UAoBsCX,SAAC,qBAK3DhE,IAAUiE,EAAAA,EAAAA,KAAA,KAAGF,UAAU,kBAAiBC,SAAEhE,KAE3C8D,EAAAA,EAAAA,MAAA,OAAKC,UAAU,gBAAeC,SAAA,EAC5BC,EAAAA,EAAAA,KAAA,UAAAD,SAAQ,UACRC,EAAAA,EAAAA,KAAA,KAAAD,SAAIpE,GAAc,yBAGpBkE,EAAAA,EAAAA,MAAA,OAAKC,UAAU,yBAAwBC,SAAA,EACrCC,EAAAA,EAAAA,KAAA,UAAAD,SAAQ,UACRC,EAAAA,EAAAA,KAAA,KAAAD,SAAIlE,GAAY,+BAK1B,C","sources":["components/VoiceParrotBot/VoiceParrotBot.jsx","api/openai.js"],"sourcesContent":["import React, { useEffect, useRef, useState } from \"react\";\r\nimport { useGoals } from \"../../context/GoalContext\";\r\nimport { getBotReply } from \"../../api/openai\";\r\nimport bot1 from \"../../assets/bot1.png\";\r\nimport \"./VoiceParrotBot.css\";\r\nimport { db } from \"../../Firebaseconfig\";\r\nimport { collection, addDoc, Timestamp } from \"firebase/firestore\";\r\n\r\nexport default function VoiceParrotBot() {\r\n  const [listening, setListening] = useState(false);\r\n  const [spokenText, setSpokenText] = useState(\"\");\r\n  const [botReply, setBotReply] = useState(\"\");\r\n  const [status, setStatus] = useState(\"\"); // show firebase save status\r\n  const recognitionRef = useRef(null);\r\n  const { addGoal } = useGoals();\r\n\r\n  useEffect(() => {\r\n    const SpeechRecognition =\r\n      window.SpeechRecognition || window.webkitSpeechRecognition;\r\n\r\n    if (!SpeechRecognition) {\r\n      alert(\"Your browser does not support Speech Recognition.\");\r\n      return;\r\n    }\r\n\r\n    const recognition = new SpeechRecognition();\r\n    recognition.lang = \"en-US\";\r\n    recognition.continuous = true;\r\n    recognition.interimResults = true;\r\n\r\n    recognition.onresult = (event) => {\r\n      let text = \"\";\r\n      for (let i = event.resultIndex; i < event.results.length; i++) {\r\n        text += event.results[i][0].transcript;\r\n      }\r\n      setSpokenText(text);\r\n\r\n      if (event.results[event.results.length - 1].isFinal) {\r\n        handleUserSpeech(text);\r\n      }\r\n    };\r\n\r\n    recognition.onend = () => setListening(false);\r\n    recognitionRef.current = recognition;\r\n  }, []);\r\n\r\n  const handleUserSpeech = async (text) => {\r\n    const lower = text.toLowerCase();\r\n\r\n    // Goal tracking\r\n    if (lower.includes(\"i want to\") || lower.includes(\"remind me to\")) {\r\n      addGoal(text);\r\n    }\r\n\r\n    // Get AI reply\r\n    let reply = \"\";\r\n    try {\r\n      reply = await getBotReply(text);\r\n    } catch (err) {\r\n      reply = \"Sorry, I couldn't process that.\";\r\n      console.error(\"OpenAI reply error:\", err);\r\n    }\r\n    setBotReply(reply);\r\n    speakText(reply);\r\n\r\n    // Store conversation in Firebase\r\n    try {\r\n      await addDoc(collection(db, \"conversations\"), {\r\n        user: text,\r\n        bot: reply,\r\n        createdAt: Timestamp.now(),\r\n      });\r\n      setStatus(\"✅ Conversation saved to Firebase!\");\r\n      console.log(\"Conversation saved to Firebase:\", { user: text, bot: reply });\r\n    } catch (error) {\r\n      setStatus(\"❌ Failed to save conversation.\");\r\n      console.error(\"Firebase save error:\", error);\r\n    }\r\n\r\n    setTimeout(() => setStatus(\"\"), 5000); // hide status after 5s\r\n  };\r\n\r\n  const startListening = () => {\r\n    if (recognitionRef.current) {\r\n      setSpokenText(\"\");\r\n      setBotReply(\"\");\r\n      recognitionRef.current.start();\r\n      setListening(true);\r\n    }\r\n  };\r\n\r\n  const stopListening = () => {\r\n    if (recognitionRef.current) {\r\n      recognitionRef.current.stop();\r\n      setListening(false);\r\n    }\r\n  };\r\n\r\n  const speakText = (text) => {\r\n    if (!window.speechSynthesis) return;\r\n    const utterance = new SpeechSynthesisUtterance(text);\r\n    utterance.lang = \"en-US\";\r\n    utterance.pitch = 1;\r\n    utterance.rate = 1;\r\n    window.speechSynthesis.speak(utterance);\r\n  };\r\n\r\n  const stopSpeaking = () => {\r\n    if (window.speechSynthesis) {\r\n      window.speechSynthesis.cancel();\r\n    }\r\n  };\r\n\r\n  return (\r\n    <div className=\"voice-bot-container\">\r\n      <div className=\"voice-bot-right\">\r\n        <img src={bot1} alt=\"Voice AI\" />\r\n      </div>\r\n      <div className=\"voice-bot-left\">\r\n        <h1>🎙 EmiBot Voice Companion</h1>\r\n        <p>Speak to EmiBot and it will respond intelligently, track your goals, and repeat your voice!</p>\r\n\r\n        <div className=\"voice-buttons\">\r\n          <button\r\n            className={listening ? \"stop-listen-btn\" : \"start-listen-btn\"}\r\n            onClick={listening ? stopListening : startListening}\r\n          >\r\n            {listening ? \"Stop Listening\" : \"Start Listening\"}\r\n          </button>\r\n          <button className=\"stop-speak-btn\" onClick={stopSpeaking}>\r\n            Stop Speaking\r\n          </button>\r\n        </div>\r\n\r\n        {status && <p className=\"firebase-status\">{status}</p>}\r\n\r\n        <div className=\"voice-textbox\">\r\n          <strong>You:</strong>\r\n          <p>{spokenText || \"Say something...\"}</p>\r\n        </div>\r\n\r\n        <div className=\"voice-textbox bot-text\">\r\n          <strong>Bot:</strong>\r\n          <p>{botReply || \"I'll reply here...\"}</p>\r\n        </div>\r\n      </div>\r\n    </div>\r\n  );\r\n}\r\n","// src/api/openai.js\r\nexport async function getBotReply(message) {\r\n  try {\r\n    const res = await fetch(\"http://localhost:5500/api/chat\", {\r\n      method: \"POST\",\r\n      headers: { \"Content-Type\": \"application/json\" },\r\n      body: JSON.stringify({ message }),\r\n    });\r\n    const data = await res.json();\r\n    return data.reply;\r\n  } catch (err) {\r\n    console.error(err);\r\n    return \"Sorry, I couldn't think of a reply.\";\r\n  }\r\n}\r\n"],"names":["VoiceParrotBot","listening","setListening","useState","spokenText","setSpokenText","botReply","setBotReply","status","setStatus","recognitionRef","useRef","addGoal","useGoals","useEffect","SpeechRecognition","window","webkitSpeechRecognition","alert","recognition","lang","continuous","interimResults","onresult","event","text","i","resultIndex","results","length","transcript","isFinal","handleUserSpeech","onend","current","async","lower","toLowerCase","includes","reply","message","res","fetch","method","headers","body","JSON","stringify","json","err","console","error","getBotReply","speakText","addDoc","collection","db","user","bot","createdAt","Timestamp","now","log","setTimeout","speechSynthesis","utterance","SpeechSynthesisUtterance","pitch","rate","speak","_jsxs","className","children","_jsx","src","bot1","alt","onClick","stopListening","stop","startListening","start","stopSpeaking","cancel"],"sourceRoot":""}